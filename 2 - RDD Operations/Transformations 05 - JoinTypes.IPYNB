{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "your 131072x1 screen size is bogus. expect trouble\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/05/25 15:40:47 WARN Utils: Your hostname, DESKTOP-0KANSSR resolves to a loopback address: 127.0.1.1; using 172.25.123.83 instead (on interface eth0)\n",
      "23/05/25 15:40:47 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/05/25 15:40:48 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType,StructField, StringType, IntegerType\n",
    "\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .getOrCreate()\n",
    "\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Joining Datasets<br>\n",
    "- Join\n",
    "- leftOuterJoin\n",
    "- rightOuterJoin\n",
    "- fullOuterJoin\n",
    "\n",
    "#### join: join(other, numPartitions=None)</br>\n",
    "When called on datasets og type (K,V), and (K,W), returns a dataset of (K, (V,W)) pairs with all pairs of elementos for each key.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating RDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ord = sc.textFile('/home/phillipefs/spark_dev/pyspark-end-to-end-developer/0 - PracticeFiles/Orders')\n",
    "ord_items = sc.textFile('/home/phillipefs/spark_dev/pyspark-end-to-end-developer/0 - PracticeFiles/Order_items')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find the subtotal for each ORDER_CUSTOMER_ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('1', '11599'), ('2', '256'), ('3', '12111'), ('4', '8827'), ('5', '11318')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get order_id and customer_id\n",
    "ord_map = ord.map(lambda x : (x.split(',')[0], x.split(',')[2]))\n",
    "ord_map.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('1', '299.98'), ('2', '199.99'), ('3', '250.0')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get order_id and value\n",
    "itens_map = ord_items.map(lambda x : (x.split(',')[0], x.split(',')[4]))\n",
    "itens_map.take(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('4', ('8827', '129.99')),\n",
       " ('10', ('5648', '299.95')),\n",
       " ('12', ('1837', '299.98')),\n",
       " ('16', ('7276', '79.95')),\n",
       " ('20', ('9198', '50.0')),\n",
       " ('24', ('11441', '199.99')),\n",
       " ('26', ('7562', '129.99')),\n",
       " ('40', ('12092', '399.98')),\n",
       " ('44', ('10500', '199.99')),\n",
       " ('50', ('5225', '79.96'))]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Join\n",
    "ord_subtotal = ord_map.join(itens_map)\n",
    "ord_subtotal.take(10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converting to Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = StructType([\n",
    "    StructField(\"id_order\", StringType(), True), \n",
    "    StructField(\"customer_value\",StructType([\n",
    "        StructField(\"id_customer\", StringType(), True),\n",
    "        StructField(\"value\", StringType(), True)\n",
    "    ]))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------+\n",
      "|id_order|customer_value|\n",
      "+--------+--------------+\n",
      "|       4|{8827, 129.99}|\n",
      "|      10|{5648, 299.95}|\n",
      "|      12|{1837, 299.98}|\n",
      "|      16| {7276, 79.95}|\n",
      "|      20|  {9198, 50.0}|\n",
      "+--------+--------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ord_subtotal.toDF(schema=schema).show(5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### cogroup: cogroup(other, numPartitions=None)</br>\n",
    "When called on datasets og type (K,V), and (K,W), returns a dataset of (k, (Interable V, Iterable W)) tuples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('4', (['8827'], ['129.99'])),\n",
       " ('10', (['5648'], ['299.95'])),\n",
       " ('12', (['1837'], ['299.98'])),\n",
       " ('16', (['7276'], ['79.95'])),\n",
       " ('20', (['9198'], ['50.0']))]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ord_map.cogroup(itens_map).map(lambda x : (x[0], tuple(map(list,x[1])))).take(5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### cartesian: cartesian(other)</br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 1), (1, 2), (1, 3), (2, 1), (2, 2), (2, 3), (3, 1), (3, 2), (3, 3)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd = sc.parallelize([1,2,3])\n",
    "rdd.cartesian(rdd).collect()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
