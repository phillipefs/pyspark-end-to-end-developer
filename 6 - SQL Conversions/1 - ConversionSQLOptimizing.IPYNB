{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/12/09 12:16:29 WARN Utils: Your hostname, DESKTOP-0KANSSR resolves to a loopback address: 127.0.1.1; using 172.18.127.6 instead (on interface eth0)\n",
      "23/12/09 12:16:29 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "23/12/09 12:16:31 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "23/12/09 12:16:31 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType, StructField, IntegerType, StringType, BooleanType, FloatType\n",
    "from pyspark.sql.functions import *\n",
    "import random\n",
    "from pyspark.sql import Row\n",
    "# Criando uma sessão Spark\n",
    "spark = SparkSession.builder.appName(\"SQL\").getOrCreate()\n",
    "\n",
    "# Criando DataFrame de clientes\n",
    "schema_clientes = StructType([\n",
    "    StructField('cliente_id', IntegerType(), True),\n",
    "    StructField('nome', StringType(), True),\n",
    "    StructField('idade', IntegerType(), True),\n",
    "    StructField('cidade', StringType(), True),\n",
    "    StructField('genero', StringType(), True)\n",
    "])\n",
    "\n",
    "clientes_data = [\n",
    "    (i, 'Cliente' + str(i), random.randint(18, 65),\n",
    "     random.choice(['São Paulo', 'Rio de Janeiro', 'Belo Horizonte', 'Brasília']),\n",
    "     random.choice(['M', 'F']))\n",
    "    for i in range(1, 1000000)\n",
    "]\n",
    "\n",
    "df_clientes = spark.createDataFrame(clientes_data, schema=schema_clientes)\n",
    "\n",
    "# Criando DataFrame de produtos\n",
    "schema_produtos = StructType([\n",
    "    StructField('produto_id', IntegerType(), True),\n",
    "    StructField('nome_produto', StringType(), True),\n",
    "    StructField('categoria', StringType(), True),\n",
    "    StructField('preco', FloatType(), True)\n",
    "   \n",
    "])\n",
    "\n",
    "produtos_data = [\n",
    "    Row(\n",
    "        produto_id=i,\n",
    "        nome_produto='Produto' + str(i),\n",
    "        categoria=random.choice(['Eletrônicos', 'Roupas', 'Alimentos', 'Acessórios']),\n",
    "        preco=random.uniform(10, 1000),  # Convertendo para float\n",
    "        disponibilidade=random.choice([True, False])\n",
    "    )\n",
    "    for i in range(1, 1000000)\n",
    "]\n",
    "\n",
    "# Criando o DataFrame de produtos\n",
    "df_produtos = spark.createDataFrame(produtos_data)\n",
    "\n",
    "# # Criando DataFrame de vendas\n",
    "schema_vendas = StructType([\n",
    "    StructField('venda_id', IntegerType(), True),\n",
    "    StructField('cliente_id', IntegerType(), True),\n",
    "    StructField('produto_id', IntegerType(), True),\n",
    "    StructField('quantidade', IntegerType(), True),\n",
    "    StructField('data_venda', StringType(), True)\n",
    "])\n",
    "\n",
    "vendas_data = [\n",
    "    (i, random.randint(1, 100), random.randint(1, 50), random.randint(1, 5), '2023-01-01')\n",
    "    for i in range(1, 1000000)\n",
    "]\n",
    "\n",
    "df_vendas = spark.createDataFrame(vendas_data, schema=schema_vendas)\n",
    "\n",
    "# Criando DataFrame de transações\n",
    "schema_transacoes = StructType([\n",
    "    StructField('transacao_id', IntegerType(), True),\n",
    "    StructField('produto_id', IntegerType(), True),\n",
    "    StructField('valor', FloatType(), True),\n",
    "    StructField('tipo', StringType(), True),\n",
    "    StructField('status', StringType(), True)\n",
    "])\n",
    "\n",
    "transacoes_data = [\n",
    "    (i, random.randint(1, 50), random.uniform(50, 500),\n",
    "     random.choice(['Débito', 'Crédito']), random.choice(['Aprovado', 'Pendente', 'Rejeitado']))\n",
    "    for i in range(1, 1000000)\n",
    "]\n",
    "\n",
    "df_transacoes = spark.createDataFrame(transacoes_data, schema=schema_transacoes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando visões temporárias para os DataFrames\n",
    "# df_clientes.createOrReplaceTempView(\"clientes_view\")\n",
    "# df_vendas.createOrReplaceTempView(\"vendas_view\")\n",
    "# df_produtos.createOrReplaceTempView(\"produtos_view\")\n",
    "# df_transacoes.createOrReplaceTempView(\"transacoes_view\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# query = \"\"\"\n",
    "#     SELECT c.nome AS cliente,t.status,\n",
    "#        COUNT(v.venda_id) AS total_vendas,\n",
    "#        AVG(p.preco) AS media_preco,\n",
    "#        COUNT(t.transacao_id) AS total_transacoes\n",
    "# FROM clientes_view c\n",
    "# INNER JOIN vendas_view v ON c.cliente_id = v.cliente_id\n",
    "# LEFT JOIN produtos_view p ON v.produto_id = p.produto_id\n",
    "# LEFT JOIN transacoes_view t ON p.produto_id = t.produto_id\n",
    "# WHERE p.disponibilidade = True\n",
    "#   AND (t.status NOT IN ('Aprovado') OR t.status IS NULL)\n",
    "# GROUP BY c.nome,t.status\n",
    "# HAVING AVG(p.preco) > 400\n",
    "#    AND COUNT(t.transacao_id) > 3;\n",
    "\n",
    "# \"\"\"\n",
    "# result = spark.sql(query)\n",
    "# result.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_produtos = df_produtos.filter(col(\"disponibilidade\")==True)\n",
    "df_transacoes = df_transacoes.filter(\"status not in ('Aprovado')\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_parcial = df_clientes.alias(\"c\").join(df_vendas.alias(\"v\"), on=col(\"c.cliente_id\") == col(\"v.cliente_id\"))\\\n",
    "    .join(df_produtos.alias('p'), col(\"v.produto_id\")==col(\"p.produto_id\"))\\\n",
    "    .join(df_transacoes.alias('t'), col(\"p.produto_id\")==col(\"t.produto_id\"))\\\n",
    "    .select(\"c.nome\", \"v.venda_id\", \"p.preco\", \"t.transacao_id\", \"t.status\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/12/09 12:18:36 WARN TaskSetManager: Stage 0 contains a task of very large size (2220 KiB). The maximum recommended task size is 1000 KiB.\n",
      "23/12/09 12:18:37 WARN TaskSetManager: Stage 1 contains a task of very large size (1175 KiB). The maximum recommended task size is 1000 KiB.\n",
      "23/12/09 12:18:38 WARN TaskSetManager: Stage 2 contains a task of very large size (2705 KiB). The maximum recommended task size is 1000 KiB.\n",
      "23/12/09 12:18:38 WARN TaskSetManager: Stage 3 contains a task of very large size (1744 KiB). The maximum recommended task size is 1000 KiB.\n",
      "[Stage 12:===================================================>    (12 + 1) / 13]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+------------+-----------------+----------------+\n",
      "|     nome|   status|total_vendas|      media_preco|total_transacoes|\n",
      "+---------+---------+------------+-----------------+----------------+\n",
      "|Cliente82|Rejeitado|    32722088|560.5068435651759|        32722088|\n",
      "|Cliente99|Rejeitado|    32724014| 562.816994260191|        32724014|\n",
      "|Cliente78|Rejeitado|    33766132|565.6189784591949|        33766132|\n",
      "| Cliente3|Rejeitado|    33709816|558.2693993277513|        33709816|\n",
      "|Cliente76|Rejeitado|    33614004|556.3282497761035|        33614004|\n",
      "| Cliente4|Rejeitado|    32389219|562.6898640081893|        32389219|\n",
      "|Cliente82| Pendente|    32694897|560.9967612305907|        32694897|\n",
      "|Cliente48|Rejeitado|    33255384| 552.383472784225|        33255384|\n",
      "|Cliente94|Rejeitado|    33315869| 561.710608960709|        33315869|\n",
      "|Cliente19| Pendente|    33410157|557.4745131439763|        33410157|\n",
      "|Cliente61|Rejeitado|    33720791|555.2121831254788|        33720791|\n",
      "|Cliente89|Rejeitado|    33350249|   560.8220340851|        33350249|\n",
      "|Cliente89| Pendente|    33331840|561.3850788281286|        33331840|\n",
      "| Cliente6|Rejeitado|    32911782|556.7749691687438|        32911782|\n",
      "|Cliente49| Pendente|    34064370|560.4464891591206|        34064370|\n",
      "|Cliente51|Rejeitado|    32842903|558.5196388418289|        32842903|\n",
      "|Cliente71|Rejeitado|    32651697|557.5951452320079|        32651697|\n",
      "|Cliente14|Rejeitado|    33364454|555.6161207306761|        33364454|\n",
      "|Cliente83|Rejeitado|    33386688| 560.968996829615|        33386688|\n",
      "| Cliente1| Pendente|    33388297|563.5404137007189|        33388297|\n",
      "+---------+---------+------------+-----------------+----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_parcial.groupBy('nome', 'status')\\\n",
    "    .agg(\n",
    "        count('venda_id').alias(\"total_vendas\"),\n",
    "        avg(\"preco\").alias(\"media_preco\"),\n",
    "        count(\"transacao_id\").alias(\"total_transacoes\")\n",
    "    )\\\n",
    "    .filter(\"total_transacoes > 3 and media_preco > 400\")\\\n",
    "    .show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
