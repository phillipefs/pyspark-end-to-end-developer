{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType, StructField, IntegerType, StringType, BooleanType, FloatType\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.window import *\n",
    "import random\n",
    "from pyspark.sql import Row\n",
    "# Criando uma sessão Spark\n",
    "spark = SparkSession.builder.appName(\"SQL\").getOrCreate()\n",
    "\n",
    "# Criando DataFrame de clientes\n",
    "schema_clientes = StructType([\n",
    "    StructField('cliente_id', IntegerType(), True),\n",
    "    StructField('nome', StringType(), True),\n",
    "    StructField('idade', IntegerType(), True),\n",
    "    StructField('cidade', StringType(), True),\n",
    "    StructField('genero', StringType(), True)\n",
    "])\n",
    "\n",
    "clientes_data = [\n",
    "    (i, 'Cliente' + str(i), random.randint(18, 65),\n",
    "     random.choice(['São Paulo', 'Rio de Janeiro', 'Belo Horizonte', 'Brasília']),\n",
    "     random.choice(['M', 'F']))\n",
    "    for i in range(1, 10000)\n",
    "]\n",
    "\n",
    "df_clientes = spark.createDataFrame(clientes_data, schema=schema_clientes)\n",
    "\n",
    "# Criando DataFrame de produtos\n",
    "schema_produtos = StructType([\n",
    "    StructField('produto_id', IntegerType(), True),\n",
    "    StructField('nome_produto', StringType(), True),\n",
    "    StructField('categoria', StringType(), True),\n",
    "    StructField('preco', FloatType(), True)\n",
    "   \n",
    "])\n",
    "\n",
    "produtos_data = [\n",
    "    Row(\n",
    "        produto_id=i,\n",
    "        nome_produto='Produto' + str(i),\n",
    "        categoria=random.choice(['Eletrônicos', 'Roupas', 'Alimentos', 'Acessórios']),\n",
    "        preco=random.uniform(10, 10000),  # Convertendo para float\n",
    "        disponibilidade=random.choice([True, False])\n",
    "    )\n",
    "    for i in range(1, 10000)\n",
    "]\n",
    "\n",
    "# Criando o DataFrame de produtos\n",
    "df_produtos = spark.createDataFrame(produtos_data)\n",
    "\n",
    "# # Criando DataFrame de vendas\n",
    "schema_vendas = StructType([\n",
    "    StructField('venda_id', IntegerType(), True),\n",
    "    StructField('cliente_id', IntegerType(), True),\n",
    "    StructField('produto_id', IntegerType(), True),\n",
    "    StructField('quantidade', IntegerType(), True),\n",
    "    StructField('data_venda', StringType(), True)\n",
    "])\n",
    "\n",
    "vendas_data = [\n",
    "    (i, random.randint(1, 10000), random.randint(1, 50), random.randint(1, 5),  random.choice(['2023-01-01', '2022-01-01', '2021-01-01']))\n",
    "    for i in range(1, 10000)\n",
    "]\n",
    "\n",
    "df_vendas = spark.createDataFrame(vendas_data, schema=schema_vendas)\n",
    "\n",
    "# Criando DataFrame de transações\n",
    "schema_transacoes = StructType([\n",
    "    StructField('transacao_id', IntegerType(), True),\n",
    "    StructField('produto_id', IntegerType(), True),\n",
    "    StructField('valor', FloatType(), True),\n",
    "    StructField('tipo', StringType(), True),\n",
    "    StructField('status', StringType(), True)\n",
    "])\n",
    "\n",
    "transacoes_data = [\n",
    "    (i, random.randint(1, 50), random.uniform(50, 500),\n",
    "     random.choice(['Débito', 'Crédito']), random.choice(['Aprovado', 'Pendente', 'Rejeitado']))\n",
    "    for i in range(1, 10000)\n",
    "]\n",
    "\n",
    "df_transacoes = spark.createDataFrame(transacoes_data, schema=schema_transacoes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando visões temporárias para os DataFrames\n",
    "df_clientes.createOrReplaceTempView(\"clientes\")\n",
    "df_vendas.createOrReplaceTempView(\"vendas\")\n",
    "df_produtos.createOrReplaceTempView(\"produtos\")\n",
    "df_transacoes.createOrReplaceTempView(\"transacoes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.window import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------+-----+------------+------------+-------+-------------------+\n",
      "|cliente_id|nome_cliente|idade|total_vendas|faixa_etaria|ranking|valor_total_compras|\n",
      "+----------+------------+-----+------------+------------+-------+-------------------+\n",
      "|      9997| Cliente9997|   54|         125|Maior que 30|      1| 3051.5832139488152|\n",
      "|      9989| Cliente9989|   53|         126|Maior que 30|      1| 1208.1925963414535|\n",
      "|      9977| Cliente9977|   27|         137| 30 ou Menos|      1|  8952.833799778895|\n",
      "|      9970| Cliente9970|   42|         147|Maior que 30|      1| 1085.7269217761611|\n",
      "|      9960| Cliente9960|   51|         130|Maior que 30|      1| 2729.0503313397444|\n",
      "|      9952| Cliente9952|   47|         145|Maior que 30|      1| 2567.1457045712677|\n",
      "|      9933| Cliente9933|   33|         131|Maior que 30|      1|  9970.298775861726|\n",
      "|      9908| Cliente9908|   60|         114|Maior que 30|      1| 1463.8195504942883|\n",
      "|      9865| Cliente9865|   63|         260|Maior que 30|      1| 2729.0503313397444|\n",
      "|      9861| Cliente9861|   53|         137|Maior que 30|      1|  8952.833799778895|\n",
      "|      9852| Cliente9852|   19|         125| 30 ou Menos|      1| 3051.5832139488152|\n",
      "|      9851| Cliente9851|   50|         124|Maior que 30|      1| 2071.5389343454726|\n",
      "|      9825| Cliente9825|   53|         137|Maior que 30|      1|  4446.552875984406|\n",
      "|      9823| Cliente9823|   45|         137|Maior que 30|      1|  2472.443889146199|\n",
      "|      9821| Cliente9821|   57|         104|Maior que 30|      1|  2340.259689182046|\n",
      "|      9819| Cliente9819|   19|         157| 30 ou Menos|      1|  5154.926826770986|\n",
      "|      9799| Cliente9799|   54|         129|Maior que 30|      1|  8973.404290025905|\n",
      "|      9792| Cliente9792|   32|         276|Maior que 30|      1|  8709.512442313257|\n",
      "|       979|  Cliente979|   57|         135|Maior que 30|      1|  9630.500615365332|\n",
      "|       977|  Cliente977|   65|         131|Maior que 30|      1|  6844.764334263731|\n",
      "+----------+------------+-----+------------+------------+-------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = \"\"\"\n",
    "   WITH VendasValidadas AS (\n",
    "    SELECT\n",
    "        v.venda_id,\n",
    "        v.cliente_id,\n",
    "        v.produto_id,\n",
    "        v.quantidade,\n",
    "        v.data_venda,\n",
    "        t.status AS status_transacao,\n",
    "        ROW_NUMBER() OVER(PARTITION BY v.cliente_id ORDER BY v.data_venda DESC) AS rn\n",
    "    FROM\n",
    "        vendas v\n",
    "    LEFT JOIN\n",
    "        transacoes t ON v.produto_id = t.produto_id\n",
    "    WHERE\n",
    "        v.data_venda LIKE '2023%'\n",
    "        AND t.status IN ('Aprovado', 'Pendente')\n",
    "        AND t.status NOT IN ('Rejeitado')\n",
    "),\n",
    "VendasClientes AS (\n",
    "    SELECT\n",
    "        c.cliente_id,\n",
    "        c.nome AS nome_cliente,\n",
    "        c.idade,\n",
    "        COUNT(vv.venda_id) AS total_vendas,\n",
    "        CASE\n",
    "            WHEN c.idade > 30 THEN 'Maior que 30'\n",
    "            ELSE '30 ou Menos'\n",
    "        END AS faixa_etaria\n",
    "    FROM\n",
    "        clientes c\n",
    "    LEFT JOIN\n",
    "        VendasValidadas vv ON c.cliente_id = vv.cliente_id\n",
    "    WHERE\n",
    "        c.cidade LIKE 'São%'\n",
    "    GROUP BY\n",
    "        c.cliente_id, c.nome, c.idade\n",
    "    HAVING\n",
    "        COUNT(vv.venda_id) > 2\n",
    "),\n",
    "TopClientes AS (\n",
    "    SELECT\n",
    "        cliente_id,\n",
    "        nome_cliente,\n",
    "        idade,\n",
    "        total_vendas,\n",
    "        faixa_etaria,\n",
    "        ROW_NUMBER() OVER(PARTITION BY cliente_id, nome_cliente, idade, total_vendas ORDER BY total_vendas DESC) AS ranking\n",
    "    FROM\n",
    "        VendasClientes\n",
    ")\n",
    "SELECT\n",
    "    tc.cliente_id,\n",
    "    tc.nome_cliente,\n",
    "    tc.idade,\n",
    "    tc.total_vendas,\n",
    "    tc.faixa_etaria,\n",
    "    tc.ranking,\n",
    "    SUM(p.preco) AS valor_total_compras\n",
    "FROM\n",
    "    TopClientes tc\n",
    "JOIN\n",
    "    VendasValidadas vv ON tc.cliente_id = vv.cliente_id\n",
    "JOIN\n",
    "    produtos p ON vv.produto_id = p.produto_id\n",
    "WHERE\n",
    "    vv.rn = 1\n",
    "GROUP BY\n",
    "    tc.cliente_id, tc.nome_cliente, tc.idade, tc.total_vendas, tc.faixa_etaria, tc.ranking\n",
    "HAVING\n",
    "    SUM(p.preco) > 1\n",
    "ORDER BY\n",
    "    tc.nome_cliente DESC, tc.ranking;\n",
    "\n",
    "\"\"\"\n",
    "result = spark.sql(query)\n",
    "result.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Valid Sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "spec_windown = Window.partitionBy(col(\"cliente_id\")).orderBy(col(\"data_venda\").desc())\n",
    "df_sales_2023 = df_vendas.filter(col(\"data_venda\").like(\"2023%\"))\n",
    "df_valid_transactions = df_transacoes.filter((col(\"status\").isin([\"Aprovado\", \"Pendente\"])) & (~col(\"status\").isin([\"Rejeitado\"])))\n",
    "\n",
    "df_valid_sales = df_sales_2023.alias(\"v\").join(\n",
    "    df_valid_transactions.alias(\"t\"), on=col(\"v.produto_id\") == col(\"t.produto_id\"), how=\"left\")\\\n",
    "    .select(\n",
    "        \"v.venda_id\",\n",
    "        \"v.cliente_id\",\n",
    "        \"v.produto_id\",\n",
    "        \"v.quantidade\",\n",
    "        \"v.data_venda\",\n",
    "        col(\"t.status\").alias(\"status_transacao\"),\n",
    "        row_number().over(spec_windown).alias(\"rn\")\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Customer Sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_customers_sp = df_clientes\\\n",
    "    .filter(col(\"cidade\").like(\"São%\"))\\\n",
    "    .withColumn(\"faixa_etaria\", when(col(\"idade\") > 30, \"Maior que 30\").otherwise(\"30 ou menos\"))\n",
    "\n",
    "df_customer_sales = df_customers_sp.alias(\"c\").join(\n",
    "    df_valid_sales.alias(\"v\"), on=col(\"c.cliente_id\") == col(\"v.cliente_id\"), how=\"left\")\\\n",
    "    .groupBy(\"c.cliente_id\", \"c.nome\", \"c.idade\")\\\n",
    "    .agg(count(\"v.venda_id\").alias(\"total_vendas\"))\\\n",
    "    .filter(\"total_vendas > 2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "675"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"\"\"\n",
    "   WITH VendasValidadas AS (\n",
    "    SELECT\n",
    "        v.venda_id,\n",
    "        v.cliente_id,\n",
    "        v.produto_id,\n",
    "        v.quantidade,\n",
    "        v.data_venda,\n",
    "        t.status AS status_transacao,\n",
    "        ROW_NUMBER() OVER(PARTITION BY v.cliente_id ORDER BY v.data_venda DESC) AS rn\n",
    "    FROM\n",
    "        vendas v\n",
    "    LEFT JOIN\n",
    "        transacoes t ON v.produto_id = t.produto_id\n",
    "    WHERE\n",
    "        v.data_venda LIKE '2023%'\n",
    "        AND t.status IN ('Aprovado', 'Pendente')\n",
    "        AND t.status NOT IN ('Rejeitado')\n",
    "),\n",
    "VendasClientes AS (\n",
    "    SELECT\n",
    "        c.cliente_id,\n",
    "        c.nome AS nome_cliente,\n",
    "        c.idade,\n",
    "        COUNT(vv.venda_id) AS total_vendas,\n",
    "        CASE\n",
    "            WHEN c.idade > 30 THEN 'Maior que 30'\n",
    "            ELSE '30 ou Menos'\n",
    "        END AS faixa_etaria\n",
    "    FROM\n",
    "        clientes c\n",
    "    LEFT JOIN\n",
    "        VendasValidadas vv ON c.cliente_id = vv.cliente_id\n",
    "    WHERE\n",
    "        c.cidade LIKE 'São%'\n",
    "    GROUP BY\n",
    "        c.cliente_id, c.nome, c.idade\n",
    "    HAVING\n",
    "        COUNT(vv.venda_id) > 2\n",
    ")\n",
    "select * from VendasClientes\n",
    "\n",
    "\"\"\"\n",
    "result = spark.sql(query)\n",
    "result.count()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
