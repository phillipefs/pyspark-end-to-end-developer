{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .getOrCreate()\n",
    "\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ord = spark.read.csv(\"/home/phillipefs/spark_dev/pyspark-end-to-end-developer/0 - PracticeFiles/Orders\", schema=\"order_id INT, order_date STRING, order_customer_id INT, order_status STRING\")\n",
    "data=(('Robert',35,40,40),('Robert',35,40,40),('Ram',31,33,29),('Ram',31,33,91))\n",
    "df_emp = spark.createDataFrame(data=data,schema=('name','score1','score2','score3'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### select(*cols)\n",
    "- select one or more columns\n",
    "- Can apply necessary functions on the selected columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+------------------+\n",
      "|   order_status|order_status_lower|\n",
      "+---------------+------------------+\n",
      "|         CLOSED|            closed|\n",
      "|PENDING_PAYMENT|   pending_payment|\n",
      "+---------------+------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_ord.select('order_status',lower('order_status').alias('order_status_lower')).show(2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### selectExpr(*expr)\n",
    "- This is a variant of select that accepts SQL expressions\n",
    "- if we want to use any functions available in SQL bot not in spark built-in functions, then we can use selectExpr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------+----+\n",
      "|order_date           |year|\n",
      "+---------------------+----+\n",
      "|2013-07-25 00:00:00.0|2013|\n",
      "+---------------------+----+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_ord.selectExpr('order_date','substring(order_date, 1, 4) as year').show(1, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----+\n",
      "|col0|col1|\n",
      "+----+----+\n",
      "|   1|   2|\n",
      "|   3|   4|\n",
      "|   5|   6|\n",
      "+----+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.range(1)\n",
    "df.selectExpr(\"stack(3, 1, 2, 3, 4, 5, 6)\").show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### withColumn(colName, col)\n",
    "- Applied transformation to only selected columns. \n",
    "- The first argument is a alias name. If we give a alias name same as column name, the transformation will apply on the same column \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+-----------------+------------+----+\n",
      "|order_id|          order_date|order_customer_id|order_status|year|\n",
      "+--------+--------------------+-----------------+------------+----+\n",
      "|       1|2013-07-25 00:00:...|            11599|      CLOSED|2013|\n",
      "+--------+--------------------+-----------------+------------+----+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_ord.withColumn(\"year\", substring(\"order_date\", 1, 4).cast('int')).show(1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### withColumnRenamed(existingCol, newCol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+-----------+------------+\n",
      "|order_id|          order_date|customer_id|order_status|\n",
      "+--------+--------------------+-----------+------------+\n",
      "|       1|2013-07-25 00:00:...|      11599|      CLOSED|\n",
      "+--------+--------------------+-----------+------------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_ord.withColumnRenamed(\"order_customer_id\", \"customer_id\").show(1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### drop(*cols)\n",
    "- drop a column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----------------+\n",
      "|order_id|order_customer_id|\n",
      "+--------+-----------------+\n",
      "|       1|            11599|\n",
      "+--------+-----------------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_ord.drop(\"order_status\", \"order_date\").show(1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### dropDuplicates(subset=None)\n",
    "- Drop duplicates rows\n",
    "- optionaly can consider only subset of columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------+------+------+\n",
      "|  name|score1|score2|score3|\n",
      "+------+------+------+------+\n",
      "|Robert|    35|    40|    40|\n",
      "|Robert|    35|    40|    40|\n",
      "|   Ram|    31|    33|    29|\n",
      "|   Ram|    31|    33|    91|\n",
      "+------+------+------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_emp.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------+------+------+\n",
      "|  name|score1|score2|score3|\n",
      "+------+------+------+------+\n",
      "|Robert|    35|    40|    40|\n",
      "|   Ram|    31|    33|    29|\n",
      "|   Ram|    31|    33|    91|\n",
      "+------+------+------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_emp.dropDuplicates().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------+------+------+\n",
      "|  name|score1|score2|score3|\n",
      "+------+------+------+------+\n",
      "|Robert|    35|    40|    40|\n",
      "|   Ram|    31|    33|    29|\n",
      "+------+------+------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_emp.dropDuplicates(subset=['name','score1','score2']).show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
